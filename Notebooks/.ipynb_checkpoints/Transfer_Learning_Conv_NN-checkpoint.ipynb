{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of a fully convolutional neural network with transfer learning\n",
    "Part of the code comes from https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson7.ipynb where different architectures are tried for the Kaggle fisheries competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import scipy\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline  \n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-16 moodel with batch normalization\n",
    "from vgg16bn import Vgg16BN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16 Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16Full = Vgg16BN().model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16Full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-16 moodel whithout activation layers\n",
    "vgg16NoTop = Vgg16BN(include_top = False).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16NoTop.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions needed for the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes the path from a directory & generates batches of augmented data for neural network input\n",
    "#The list of classes will be automatically inferred from the subdirectory names/structure under directory, \n",
    "#where each subdirectory will be treated as a different class \n",
    "#(and the order of the classes, which will map to the label indices, will be alphanumeric). \n",
    "#\"categorical\" will be 2D one-hot encoded labels,\n",
    "def get_batches(dirname, gen=ImageDataGenerator(), shuffle=True, batch_size=4, class_mode='categorical',\n",
    "                target_size=(224,224)):\n",
    "    return gen.flow_from_directory(dirname, target_size=target_size,\n",
    "            class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather data from path to batches (shuffle is False thus data in batch will stay at same position)\n",
    "def get_data(path, target_size=(224,224)):\n",
    "    batches = get_batches(path, shuffle=False, batch_size=1, class_mode=None, target_size=target_size)\n",
    "    return np.concatenate([batches.next() for i in range(batches.samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts a class vector (integers) to binary class matrix same as one hot encoding\n",
    "def onehot(x):\n",
    "    #from Keras\n",
    "    return to_categorical(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_plot(img):\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        return np.rollaxis(img, 0, 1).astype(np.uint8)\n",
    "    else:\n",
    "        return np.rollaxis(img, 0, 3).astype(np.uint8)\n",
    "\n",
    "def plot(img):\n",
    "    plt.imshow(to_plot(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get class label for each data in batches\n",
    "def get_classes(path):\n",
    "    batches = get_batches(path+'train', shuffle=False, batch_size=1)\n",
    "    val_batches = get_batches(path+'validation', shuffle=False, batch_size=1)\n",
    "    return (val_batches.classes, batches.classes, onehot(val_batches.classes), onehot(batches.classes),\n",
    "        val_batches.filenames, batches.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the model at the index containing last convolutional layer in order to retrieve the input size of \n",
    "#the new implemented network for the training\n",
    "def split_at(model, layer_type):\n",
    "    layers = model.layers\n",
    "    layer_idx = [index for index,layer in enumerate(layers)\n",
    "                 if type(layer) is layer_type][-1]\n",
    "    return layers[:layer_idx+1], layers[layer_idx+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for train and validation data\n",
    "path='./'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, val_filenames, filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = get_data(path+'train')\n",
    "val = get_data(path+'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(trn[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction of vgg16 model whithout activation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = Vgg16BN(include_top = False).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove last layer which is a maxPooling layer\n",
    "vgg16.pop()\n",
    "vgg16.input_shape, vgg16.output_shape\n",
    "vgg16.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input = shape of the image (224x224 with 3 RGB layers)\n",
    "#Output = size of feature shape from the sequence of convolutional layers\n",
    "vgg16.input_shape, vgg16.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict features for training and validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_val_feat = vgg16.predict(val, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_trn_feat = vgg16.predict(trn, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_val_feat.shape, conv_trn_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save features or import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names of the files for the saving and the loading below in this notebook are differents (but should be the same) in order to not erase previously computed features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('conv_val_feat.pkl','wb')\n",
    "pkl.dump(conv_val_feat, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('conv_trn_feat.pkl','wb')\n",
    "pkl.dump(conv_trn_feat, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_val_feat = pkl.load( open(\"conv_val.pkl\", \"rb\"))\n",
    "conv_trn_feat = pkl.load( open(\"conv_trn.pkl\", \"rb\"))\n",
    "conv_val_feat.shape, conv_trn_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a fully convolutional network taking as input the above features \n",
    "## With global average pooling as final layer\n",
    "This solution was not taked into account as whitout the global average pooling we seem to have better visual results (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D, Activation, Dropout\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers,_ = split_at(vgg16, Convolution2D)\n",
    "conv_layers[-1].output_shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of filters and dropout probability\n",
    "nf=128; p=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the rest of the architecture that will take as input \n",
    "#the features computed at the last convolutional layer of vgg16\n",
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((1,2)),\n",
    "        Convolution2D(2,3,3, border_mode='same'),\n",
    "        Dropout(p),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model = Sequential(get_lrg_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training of the fully convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history_lrg = lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=6, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show heatmap of last convolutional layer (better below)\n",
    "Grabs the output of last convolutional layer (which is the 4th-last layer of our model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = lrg_model.layers\n",
    "conv_fn = K.function([l[0].input, K.learning_phase()], [l[-4].output])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Original cm function but does not seem to work\n",
    "def get_cm(inp, label):\n",
    "    conv = conv_fn([inp,0])[0, label]\n",
    "    return scipy.misc.imresize(conv, (224,224), interp='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified one\n",
    "def get_cm(inp, label):\n",
    "    '''Convert the 4x4 layer data to a 75x75 image.'''\n",
    "    conv = np.rollaxis(conv_fn([inp,0])[0][0],2,0)[label]\n",
    "    return scipy.misc.imresize(conv, (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have to add an extra dimension to our input since the CNN expects a 'batch' (even if it's just a batch of one).\n",
    "inp = np.expand_dims(conv_val_feat[330],0)\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(lrg_model.predict(inp)[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(to_plot(val[330]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully convolutional neural network heatmap\n",
    "## Whithout global average pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = Vgg16BN(include_top = False).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.pop()\n",
    "vgg16.input_shape, vgg16.output_shape\n",
    "vgg16.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers,_ = split_at(vgg16, Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of filters\n",
    "nf=128;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(2,3,3, border_mode='same'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model = Sequential(get_lrg_layers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lrg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training is done in two parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_lrg2 = lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=6, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the learned weights\n",
    "Again files names are not the same below in order to not erase previously computed weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model.save_weights('my_model_weights.h5_not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = lrg_model.layers\n",
    "conv_fn = K.function([l[0].input, K.learning_phase()], [l[-3].output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show heatmap of last convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this one !\n",
    "def get_cm2(inp, label):\n",
    "    '''Convert the 4x4 layer data to a 75x75 image.'''\n",
    "    conv = np.rollaxis(conv_fn([inp,0])[0][0],0)[label]\n",
    "    return scipy.misc.imresize(conv, (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.expand_dims(conv_val_feat[330], 0)\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(to_plot(val[330]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = get_cm2(inp, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cm, cmap=\"cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plot(val[330])\n",
    "plt.imshow(cm, cmap=\"cool\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a dataframe to store and display the images as well as their respective activation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"image\", \"pred\",\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store all the images (from the validation set) as well as their prediction and their reshaped size for heatmap computation\n",
    "imageList = []\n",
    "predList = []\n",
    "inptList = []\n",
    "for i in range(val.shape[0]):\n",
    "    imageList.append(val[i])\n",
    "    inpt = np.expand_dims(conv_val_feat[i], 0)\n",
    "    pred = np.round(lrg_model.predict(inpt)[0],2)[1]\n",
    "    inptList.append(inpt)\n",
    "    predList.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"image\"] = imageList\n",
    "df[\"pred\"] = predList\n",
    "df[\"input\"] = inptList\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort rows in the dataframe in prediction order for the first label\n",
    "df2 = df.sort_values(by = \"pred\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save positively labeled images with their corresponding activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df2['pred'] >= 0.5\n",
    "filteredDf = df2[positive]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  whitout activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for image in filteredDf[\"image\"]:\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(1, 1, forward=False)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    ax.imshow(to_plot(image))\n",
    "    fig.savefig('./verification/image'+str(i)+'.png',dpi=224)\n",
    "    i+=1\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in df2.iterrows():\n",
    "    cm2 = get_cm2(row['input'],1)\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(1, 1, forward=False)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    ax.imshow(to_plot(row['image']))\n",
    "    ax.imshow(cm2, cmap=\"cool\", alpha=0.5)\n",
    "    fig.savefig('./verificationWA/image'+str(i)+'.png',dpi=224)\n",
    "    i+=1\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poster creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scale = 3\n",
    "inches_A2 = (23.39 * scale, 16.53 * scale) \n",
    "fig, ax = plt.subplots(15,24,figsize=inches_A2) \n",
    "#fig, ax = plt.subplots(2,5, figsize = inches_A2)\n",
    "axs = ax.ravel()\n",
    "i = 0\n",
    "for image in df2[\"image\"]:\n",
    "    inp2 = np.expand_dims(image, 0)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(to_plot(image))\n",
    "    i+=1\n",
    "\n",
    "fig.savefig('poster_validation.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 3\n",
    "inches_A2 = (23.39 * scale, 16.53 * scale) \n",
    "fig, ax = plt.subplots(15,24,figsize=inches_A2) \n",
    "#fig, ax = plt.subplots(2,5, figsize = inches_A2)\n",
    "axs = ax.ravel()\n",
    "i = 0\n",
    "for index, row in df2.iterrows():\n",
    "    cm2 = get_cm2(row['input'],1)\n",
    "    #plot(row['image'])\n",
    "    #plt.imshow(cm2, cmap=\"cool\", alpha=0.5)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(to_plot(row['image']))\n",
    "    axs[i].imshow(cm2, cmap=\"cool\", alpha=0.5)\n",
    "    i+=1\n",
    "\n",
    "fig.savefig('poster5.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predVal = lrg_model.predict_classes(conv_val_feat)\n",
    "predVal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels_bin = [x[1] for x in val_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(validation_labels_bin, predVal )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"0\",\"1\"]\n",
    "plot_confusion_matrix(conf_mat, class_names, title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, class_names, normalize=True, title='Normalized confusion matrix')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
